import os
import numpy as np
import pandas as pd
import math
from collections import defaultdict, Counter

class NaiveBayesTextClassifier:
    def __init__(self, vocab_size=10000, alpha=1.0):
        self.vocab_size = vocab_size
        self.alpha = alpha
        self.vocab = None
        self.word_probs = None
        self.class_probs = None

    def tokenize(self, text):
        # Simple tokenizer: lowercase and split by non-alphabetic characters
        words = text.lower().split()
        return [word.strip('.,!?;()[]') for word in words if word.isalpha()]

    def build_vocab(self, texts):
        # Flatten all words from all documents
        word_counts = Counter(word for text in texts for word in self.tokenize(text))
        # Keep the most common `vocab_size` words
        vocab = {word: i for i, (word, _) in enumerate(word_counts.most_common(self.vocab_size))}
        self.vocab = vocab

    def text_to_vector(self, text):
        # Convert text into binary feature vector based on vocab
        vector = np.zeros(len(self.vocab))
        for word in self.tokenize(text):
            if word in self.vocab:
                vector[self.vocab[word]] = 1
        return vector

    def train(self, train_texts, train_labels):
        num_docs = len(train_texts)
        num_pos_docs = sum(train_labels)
        num_neg_docs = num_docs - num_pos_docs

        # Initialize word counts and document class counts
        pos_word_count = np.zeros(len(self.vocab))
        neg_word_count = np.zeros(len(self.vocab))

        # Count words in positive and negative documents
        for i in range(num_docs):
            vector = self.text_to_vector(train_texts[i])
            if train_labels[i] == 1:
                pos_word_count += vector
            else:
                neg_word_count += vector

        # Total words in positive and negative documents
        total_pos_words = pos_word_count.sum()
        total_neg_words = neg_word_count.sum()

        # Compute probabilities P(word|pos) and P(word|neg) with Laplace smoothing
        self.word_probs = {
            'pos': (pos_word_count + self.alpha) / (total_pos_words + self.alpha * len(self.vocab)),
            'neg': (neg_word_count + self.alpha) / (total_neg_words + self.alpha * len(self.vocab))
        }

        # Class priors P(pos) and P(neg)
        self.class_probs = {
            'pos': num_pos_docs / num_docs,
            'neg': num_neg_docs / num_docs
        }

    def predict(self, text):
        vector = self.text_to_vector(text)
        log_prob_pos = math.log(self.class_probs['pos'])
        log_prob_neg = math.log(self.class_probs['neg'])

        # Sum up log probabilities of each word given the class
        for i, word_presence in enumerate(vector):
            if word_presence == 1:
                log_prob_pos += math.log(self.word_probs['pos'][i])
                log_prob_neg += math.log(self.word_probs['neg'][i])

        # Choose the class with the higher probability
        return 1 if log_prob_pos > log_prob_neg else 0

    def predict_all(self, texts):
        return [self.predict(text) for text in texts]


def load_data(data_dir, split):
    texts = []
    labels = []
    label_file = os.path.join(data_dir, f'{split}_labels.csv')
    df = pd.read_csv(label_file)
    for _, row in df.iterrows():
        review_path = os.path.join(data_dir, row['review'])
        with open(review_path, 'r', encoding='utf-8') as file:
            texts.append(file.read())
        labels.append(row['sentiment'])
    return texts, labels



def evaluate_model(predictions, labels):
    # Calculate accuracy, precision, recall, and F1 score
    tp = sum((p == 1) and (l == 1) for p, l in zip(predictions, labels))
    tn = sum((p == 0) and (l == 0) for p, l in zip(predictions, labels))
    fp = sum((p == 1) and (l == 0) for p, l in zip(predictions, labels))
    fn = sum((p == 0) and (l == 1) for p, l in zip(predictions, labels))

    accuracy = (tp + tn) / len(labels)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return accuracy, precision, recall, f1

def save_predictions(file_path, predictions):
    df = pd.DataFrame({'sentiment': predictions})
    df.to_csv(file_path, index=False)

def main(data_src):
    # Load training and validation data
    train_texts, train_labels = load_data(data_src, 'train')
    val_texts, val_labels = load_data(data_src, 'val')

    # Initialize and train the classifier
    classifier = NaiveBayesTextClassifier(vocab_size=10000)
    classifier.build_vocab(train_texts)
    classifier.train(train_texts, train_labels)

    # Validate the model
    val_predictions = classifier.predict_all(val_texts)
    accuracy, precision, recall, f1 = evaluate_model(val_predictions, val_labels)

    print(f"Validation Accuracy: {accuracy:.4f}")
    print(f"Validation Precision: {precision:.4f}")
    print(f"Validation Recall: {recall:.4f}")
    print(f"Validation F1: {f1:.4f}")

    # Save validation predictions
    save_predictions(os.path.join(data_src, 'val_predictions.csv'), val_predictions)

    # Load test data and make predictions
    test_texts, _ = load_data(data_src, 'test')
    test_predictions = classifier.predict_all(test_texts)

    # Save test predictions
    save_predictions(os.path.join(data_src, 'test_predictions.csv'), test_predictions)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description="Naive Bayes Text Classifier")
    parser.add_argument('--data_src', type=str, required=True, help='Directory containing train, val, and test data')
    args = parser.parse_args()

    main(args.data_src)
